\documentclass[11pt,a4wide]{article}
\usepackage{verbatim}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{a4wide}
\usepackage{color}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[dvips]{epsfig}
\usepackage[T1]{fontenc}
\usepackage{cite} % [2,3,4] --> [2--4]
\usepackage{shadow}
\usepackage{hyperref}

\setcounter{tocdepth}{2}

\usepackage{subcaption}

\lstset{language=c++}
\lstset{alsolanguage=[90]Fortran}
\lstset{basicstyle=\small}
\lstset{backgroundcolor=\color{white}}
\lstset{frame=single}
\lstset{stringstyle=\ttfamily}
\lstset{keywordstyle=\color{red}\bfseries}
\lstset{commentstyle=\itshape\color{blue}}
\lstset{showspaces=false}
\lstset{showstringspaces=false}
\lstset{showtabs=false}
\lstset{breaklines}



%lager heftig forside:
\newcommand*{\titleAT}{\begingroup % Create the command for including the title page in the document
\newlength{\drop} % Command for generating a specific amount of whitespace
\drop=0.1\textheight % Define the command as 10% of the total text height

\rule{\textwidth}{1pt}\par % Thick horizontal line
\vspace{2pt}\vspace{-\baselineskip} % Whitespace between lines
\rule{\textwidth}{0.4pt}\par % Thin horizontal line

\vspace{0.5\drop} % Whitespace between the top lines and title
\centering % Center all text
\textcolor{black}{ % Red font color
{\Huge Studying second order phase transitions by using the Ising model in two dimentions and the metropolis algorithm}\\[0.75\baselineskip] % Title line 1
%{\Large Tema:}\\[0.75\baselineskip] % Title line 2
%{\Huge Lydmåling og hørselstesting} % Title line 3
} 

\vspace{0.25\drop} % Whitespace between the title and short horizontal line
\rule{0.3\textwidth}{0.4pt}\par % Short horizontal line under the title
\vspace{0.25\drop} % Whitespace between the thin horizontal line and the author name

{\Large \textsc{Project 4, FYS-3150\\[0.75\baselineskip] \normalsize{Ina K. B. Kullmann}
}}\par % Author name

%\vfill % Whitespace between the author name and publisher text

\vspace{0.25\drop} % Whitespace between the title and short horizontal line
\rule{0.3\textwidth}{0.4pt}\par % Short horizontal line under the title
\vspace{0.25\drop} % Whitespace between the thin horizontal line and the author name

\begin{abstract}
The aim of this project is to numerically solve ..... by using the .... algorithm. 


the Ising model in two dimensions, without an external magnetic 
field

Title: Studying phase transitions (critical T) using the ising model (metropolis alg)?

compare teory, lars onsager



%Before solving the problem for two electrons we will look at a simpler system, one electron in a three-dimensional harmonic oscillator potential. Then we will move on to the two electrons in a three-dimensional harmonic oscillator, but first without the Coulomb interaction. For each case we will reformulate the Schr\"odingers equation for this system to a dimentionless form and then to a descrete eigenvalue equation. This eigenvalue problem will we solve numerically with the Jacobi rotation algorithm and compare with the Armadillo library functions for the one electron system. 

%The Jacobi rotation algorithm will be implemented numerically on a general form so that it can be applied to any eigenvalue problem with a symetrix matix. We will test the implementation of the Jacobi method on an arbitrary symetric matrix before moving on to solve the physical problems. 

%When the procedure used on the two simplest cases are tested and understood we will apply the metods on the two electron system with a Coulomb interaction and plot the probability distrubution for different strengths of the interaction. 
\end{abstract}
\vspace*{0.25\drop} % Whitespace under the publisher text

\begin{center}
{ \scriptsize \noindent All source codes can be found at: \texttt{https://github.com/inakbk/Project\_2}. }
\end{center}

\rule{\textwidth}{0.4pt}\par % Thin horizontal line
\vspace{2pt}\vspace{-\baselineskip} % Whitespace between lines
\rule{\textwidth}{1pt}\par % Thick horizontal line

\endgroup}
%kode slutt for heftig forside


\begin{document}
%\maketitle
\titleAT % This command includes the title page


\newpage
\tableofcontents
\newpage

\section{Motivation and purpose}


\section{Theory}
something about phase transitions and therefore chi and heat capacity is relevant


\subsection{The Ising model in two dimentions}

The Ising model is a simple model for ferromagnetism in statistical physics. The model consists of magnetic spins that are allowed to interact with its neigbours. The magnetic dipole moments are allowed to have two values, 1 and -1.

In this project we will study the ising model i two dimentions wich allows the identification of phase transitions (define). We will also set the external magnetic field to zero troughout this paper.
% in two dimensions second order phase transition. 

%\subsection{Phase transitions} %?


The Ising model gives that the energy (for the whole system?) can be expressed as
\begin{equation}
  E=-J\sum_{<kl>}^{N}s_ks_l
\end{equation}
where the value of the spins are  $s_k=\pm 1$ and $N$ is the total number of spins. The variable $J$ is a coupling constant expressing the strength of the interaction between neighboring spins.

The symbol $<kl>$ indicates that we sum over nearest neighbors only. We will assume that we have a ferromagnetic ordering, viz $J> 0$ and use periodic boundary conditions. 

(invlude matrix of spins and define variable $L$, $N$ and $M$)

%analytical values to test:
First we assume that there is only two spins in each dimention (x and y), we set $L=2$. Then the closed form expression for the partition function is given by:
\[
Z = \sum_{i=1}^M e^{-\beta E_i}
\]
where $M$ is the number of microstates or combinations of spins.


\subsection{L=2 analytical values}

$N = L\cdot L = 4$

There is $M= L^N = 2^N = 16$ microstates, or possible combinations and energies of the spin system. So to calculate the partition function we have to find the energies:
\[
Z = e^{-\beta E_1} + ... e^{-\beta E_{16}}
\]

The spin system can be visualized as 16 matrices on the form:
$\left[ \begin{array}{cc} s(0,0) & s(0,1) \\
                             	    s(1,0)  & s(1,1) \\
\end{array} \right]$
with corresponding energies. 

Periodic boundaryconditions give that every spin has a neighbour. The neighbours of the spin $s(1,1)$ is  $s(0,1)$ twice (above and below) and $s(1,0)$ twice (above and below). To find the energy we have to sum over the nearest neighbours for all the spins in the system. The product $s_ls_k$ of two neighbours should only be calculated once. This is solved if the index of $s_l$ is fixed while $s_k$ has one higher index in each direction at a time:

\begin{align}
E &= -J\bigg( s(0,0)\cdot \big[s(1,0) + s(0,1) \big] + s(0,1)\cdot\big[s(1,1) + s(0,0) \big] \nonumber   \\ 
 &+ s(1,0)\cdot\big[s(0,0) + s(1,1) \big] + s(1,1)\cdot\big[s(0,1) + s(1,0) \big] \bigg)
 \label{eq: energy spins}
\end{align}

The 16 states with corresponding energies calculated with equation \ref{eq: energy spins} is then: \\
\begin{tabular}{cccc}
$E_1 = 0$ & $E_2 = 0$ & $E_3 = 0$& $E_4 = 0$ \\ 
$\left[ \begin{array}{cc} 1 & 1 \\
                             	    -1  & -1 \\
\end{array} \right]$ & 
$
\left[ \begin{array}{cc} 1 & -1 \\
                             	    1  & -1 \\
\end{array} \right]$ &
$
\left[ \begin{array}{cc} -1 & 1 \\
                             	    -1  & 1 \\
\end{array} \right]$ & 
$
\left[ \begin{array}{cc} -1 & -1 \\
                             	    1  & 1 \\
\end{array} \right] $ \\
$E_5 = 0$ & $E_6 = 0$ & $E_7 = 0$& $E_8 = 0$ \\ 
$
\left[ \begin{array}{cc} 1 & 1 \\
                             	    1  & -1 \\
\end{array} \right]$ &
$
\left[ \begin{array}{cc} 1 & 1 \\
                             	    -1  & 1 \\
\end{array} \right]$ &
$
\left[ \begin{array}{cc} 1 & -1 \\
                             	    1  & 1 \\
\end{array} \right]$ &
$
\left[ \begin{array}{cc} -1 & 1 \\
                             	    1  & 1 \\
\end{array} \right]$ \\
$E_9 = 0$ & $E_{10} = 0$ & $E_{11} = 0$& $E_{12} = 0$ \\ 
$
\left[ \begin{array}{cc} -1 & -1 \\
                             	    -1  & 1 \\
\end{array} \right]$ &
$
\left[ \begin{array}{cc} -1 & -1 \\
                             	    1  & -1 \\
\end{array} \right]$ &
$
\left[ \begin{array}{cc} 1 & -1 \\
                             	    -1  & -1 \\
\end{array} \right]$ &
$
\left[ \begin{array}{cc} -1 & 1 \\
                             	    -1  & -1 \\
\end{array} \right]$ \\
$E_{13} = 8J$ & $E_{14} = 8J$ & $E_{15} = -8J$& $E_{16} = -8J$ \\ 
$
\left[ \begin{array}{cc} 1 & -1 \\
                             	    -1  & 1 \\
\end{array} \right]$ &
$
\left[ \begin{array}{cc} -1 & 1 \\
                             	    1  & -1 \\
\end{array} \right]$ &
$
\left[ \begin{array}{cc} -1 & -1 \\
                             	    -1  & 1 \\
\end{array} \right]$ &
$
\left[ \begin{array}{cc} 1 & 1 \\
                             	    1  & 1 \\
\end{array} \right]$
\end{tabular}
\\
We then see that there is only three possible values for the energies, $E \in \{-8J, 0, 8J\}$ with corresponding multiplicity $\{2, 12, 2\}$. The partition function can then be calculated:
\begin{align*}
Z &= 2e^{-\beta (-8J)} + 12e^{-\beta \cdot 0} + 2 e^{-\beta \cdot 8J} = 2(e^{\beta \cdot 8J}  + e^{-\beta \cdot 8J}) + 12 \\
&= 4\cosh(8J\beta) + 12
\end{align*}
using that $\cosh(x) = \frac{1}{2}(e^{-x} + e^x)$.

Now that we have the partition function various expectation variables can be calculated. We start with the expectation value for the energy:
\begin{align*}
\langle E \rangle &= \frac{1}{Z} \sum_{i=1}^M E_ie^{-\beta E_i} = \frac{1}{Z} \big[ 2\cdot (-8J)e^{8J\beta} + 0 + 2\cdot 8Je^{-8J\beta}\big] = \frac{1}{Z} \big[-16Je^{8J\beta} + 16Je^{-8J\beta}\big] \\
&= -\frac{16J}{Z}\big[-e{-8J\beta} + e^{8J\beta}\big] = -\frac{32J}{Z}\sinh(8J\beta) = -\frac{8J\sinh(8J\beta)}{\cosh(8J\beta) + 3}
\end{align*}
using that $\sinh(x) = \frac{1}{2}(-e^{-x} + e^x)$. We will now calculate the heat capacity 
\[
C_v = \frac{1}{k_bT}\sigma_E^2 =  \frac{1}{k_bT}\big(\langle E^2 \rangle - \langle E \rangle^2\big)
\]
where
\begin{align*}
\langle E^2 \rangle &= \frac{1}{Z} \sum_{i=1}^M E_i^2 e^{-\beta E_i} = \frac{1}{Z} \big[ 2\cdot (-8J)^2 e^{8J\beta} + 0 + 2\cdot (8J)^2 e^{-8J\beta}\big] = \frac{128J^2}{Z} \big[ e^{8J\beta} + e^{-8J\beta}\big] \\
&= \frac{128J^2 \cdot 2\cosh(8J\beta)}{4\cosh(8J\beta) + 12} =  \frac{64J^2 \cosh(8J\beta)}{\cosh(8J\beta) + 3}
\end{align*}
so that 
\begin{align*}
C_v &= \frac{1}{k_bT}\bigg[ \frac{64J^2 \cosh(8J\beta)}{\cosh(8J\beta) + 3} - \bigg(  -\frac{8J\sinh(8J\beta)}{\cosh(8J\beta) + 3} \bigg)^2 \bigg] = \frac{1}{k_bT}\bigg[ \frac{64J^2 \cosh(8J\beta)}{\cosh(8J\beta) + 3} - \frac{64J^2 \sinh^2(8J\beta)}{(\cosh(8J\beta) + 3)^2} \bigg] \\
&= \frac{64J^2}{k_bT}\bigg[ \frac{ \cosh(8J\beta)(\cosh(8J\beta) + 3)-  \sinh^2(8J\beta)}{(\cosh(8J\beta) + 3)^2} \bigg] = \frac{64J^2}{k_bT}\bigg[ \frac{\cosh^2(8J\beta) + 3\cosh^2(8J\beta) - \sinh^2(8J\beta)}{(\cosh(8J\beta) + 3)^2} \bigg] \\
&= \frac{64J^2\beta}{T} \bigg[\frac{1 + 3\cosh(8J\beta)}{(\cosh(8J\beta) + 3)^2} \bigg]
\end{align*}

We define the magnetization $\mathcal{M}$ as the sum of all the spins $s$. It is easy to see that for the $2\times 2$ system there are only 5 possible values for the magnetization, $\mathcal{M} \in \{-4, -2, 0, 2, 4\}$.  The corresponding energy and multiplicity is given in table \ref{tab: multiplic}. 

\begin{tabular}{|c|c|c|c|}
\hline 
\# spins up & Multiplicy & Energy & Magnetization \\ 
\hline 
4 & 1 & -8J & 4 \\ 
\hline 
3 & 4 & 0 & 2 \\ 
\hline 
2 & 4 & 0 & 0 \\ 
\hline 
2 & 2 & 8J & 0 \\ 
\hline 
1 & 4 & 0 & -2 \\ 
\hline 
0 & 1 & -8J & -4 \\ 
\hline 
\end{tabular} \label{tab: multiplic}

The expectation value of the magnetization and the magnetization squared can be calculated as
\begin{align}
\langle \mathcal{M} \rangle &= \frac{1}{Z}\sum_{i=1}^M \mathcal{M}  e^{-\beta E_i} \label{eq: exp M} \\
\langle \mathcal{M}^2 \rangle &= \frac{1}{Z}\sum_{i=1}^M \mathcal{M}^2  e^{-\beta E_i} \nonumber
\end{align}
which we can use to calculate the suceptibility, the parameter of special interest: 
\[
\chi = \frac{1}{k_bT}\sigma_\mathcal{M} = \frac{1}{k_bT}\big( \langle \mathcal{M}^2 \rangle - \langle \mathcal{M} \rangle^2 \big).
\]
When looking at equation \ref{eq: exp M} and table \ref{tab: multiplic} we quicly see that the expectation value of the magnetization is zero for all temperatures. The microstates whith oposite magnetization have the same multiplicity so they cancel each other out. When running numerical calculations on large systems, for large $L$, the numerical value of $\langle \mathcal{M} \rangle$ will not reach zero unless the simulation is run for a (extremely) long time. This is because it takes a long time for the simulation to go through all the possible microstates after the simulation have reached a very probable state. But we want to have a reasonable measure of the magnetization and suceptibility for large systems and at the same time minimize the excecution time of the numerical simulation. To do this we choose to use the absolute value of the magnetization in the definition of the suceptibility. 

There are 3 possible values for the absolute value of the magnetization, $|\mathcal{M}| \in \{0, 2, 4\}$.  The corresponding energy and multiplicity is given in table \ref{tab: multiplic2}. 

\begin{tabular}{|c|c|c|}
\hline 
Absolute Magnetization & Energy &  Multiplicy\\ 
\hline 
4 & -8J & 2 \\ 
\hline 
2 & 0 & 8 \\ 
\hline 
0 & 0 & 4 \\ 
\hline 
0 & 8J & 2 \\ 
\hline 
\end{tabular} \label{tab: multiplic2}

We are then ready to calculate the expectation value of the absolute value of the magnetization by using the multiplicity for each energy and corresponding magnetization:
\begin{align}
\langle |\mathcal{M}| \rangle &= \frac{1}{Z}\sum_{i=1}^M |\mathcal{M}|  e^{-\beta E_i} = \frac{1}{Z} \bigg( 2\cdot 4e^{-\beta(-8J)} + 8\cdot 2e^0 + 0\cdot4e^0 + 0\cdot 2e^{-\beta 8J} \bigg)\nonumber \\
&= \frac{8}{Z}\big(e^{8J\beta} + 2\big) = \frac{8(e^{8J\beta} + 2)}{4\cosh(8j\beta) + 12} = \frac{2(e^{8J\beta}+ 2)}{\cosh(8j\beta) + 3}.
\label{eq: exp absM} 
\end{align}
We also obtain the expectation value of the square of the magnetization:
\begin{align*}
\langle \mathcal{M}^2 \rangle &= \frac{1}{Z}\sum_{i=1}^M \mathcal{M}^2 e^{-\beta E_i} = \frac{1}{Z}\big( 2\cdot 4^2 e^{-\beta (-8J)} + 8\cdot 2^2e^0 + 0 + 0 \big) = \frac{32}{Z}\big( e^{8J\beta} + 1 \big) \\
&= \frac{8\big(e^{8J\beta} + 1\big)}{\cosh(8J\beta) + 3}.
\end{align*}
And finally the suceptibility is given by
\begin{align*}
\chi &= \frac{1}{k_bT}\big( \langle \mathcal{M}^2 \rangle - \langle |\mathcal{M}| \rangle^2 \big) = \frac{1}{k_bT}\bigg[ \frac{8(e^{8J\beta} + 1)}{\cosh(8J\beta) + 3} - \bigg( \frac{2(e^{8J\beta}+ 2)}{\cosh(8j\beta) + 3} \bigg)^2 \bigg] \\
&= \frac{1}{k_bT}\bigg[ \frac{8(e^{8J\beta} + 1\big)(\cosh(8j\beta) + 3) - 4(e^{8J\beta}+ 2)^2}{(\cosh(8j\beta) + 3)^2} \bigg] \\
&= 4\beta \bigg[ \frac{2(e^{8J\beta} + 1\big)(\cosh(8j\beta) + 3) - (e^{8J\beta}+ 2)^2}{(\cosh(8j\beta) + 3)^2} \bigg] 
\end{align*}

\subsection{Units, scaled parameters}
We will now write the equations for the expectation values, the heat capacity and the susceptibility in terms of a scaled temperature
\begin{align*}
T' &= T \frac{k_b}{J} \\
\Rightarrow T &= T'\frac{J}{k_b}\\
\Rightarrow \beta &= \frac{1}{k_bT} = \frac{1}{k_b\cdot T'\frac{J}{k_b}} = \frac{1}{T'J}
\end{align*}
We then set $J=1$ so that:
\[
\beta = \frac{1}{T'}
\]
We will use this new temperature $T'$ in the numerical calculations. We also scale the heat capacity as:
\[
C_v' = \frac{C_v}{k_b} = \frac{64}{T'^2} \frac{1 + 3\cosh(8/T')}{(\cosh(8/T') + 3)^2} 
\]
In terms of $T'$ the expectation values and the susceptibility for the $2\times 2$ system can be written as:
\begin{align}
\langle E \rangle &= -\frac{8\sinh(8/T')}{\cosh(8/T') + 3} \\
\langle E^2 \rangle &=\frac{64J^2 \cosh(8/T')}{\cosh(8/T') + 3} \\
\langle |\mathcal{M}| \rangle &= \frac{2(e^{8/T'}+ 2)}{\cosh(8/T') + 3}\\
\langle \mathcal{M}^2 \rangle &= \frac{8\big(e^{8/T'} + 1\big)}{\cosh(8/T') + 3} \\
\chi &= \frac{4}{T'} \frac{2(e^{8/T'} + 1\big)(\cosh(8/T') + 3) - (e^{8/T'}+ 2)^2}{(\cosh(8/T') + 3)^2} 
\end{align}
These theoretical values will be used to test the implementation of the numerical method for the $L=2$ system. 

%theory mc methods/metropolis
%explaination of code

\section{Numerical methods}
bla bla theory and the programs
\subsection{Metropolis algorithm}
See notes?

Start out with an initial state, random or ordered

\begin{enumerate}
\item The system are in a spin state with energy E
\item Create a trial state with the trial energy $E_t$ by flipping one spin
\item Compute $\Delta E = E_t - E$
\begin{itemize}
\item If $\Delta E \leq 0$
\begin{itemize}
\item Accept the trial state as the new state 
\end{itemize}
\item If $\Delta E >0$ calculate $w = e^{-\beta \Delta E}$ and create a random number $r$
\begin{itemize}
\item If $r\leq w$ (the metropolis test): Accept the trial state as the new state 
\item Else discard the trial state (do nothing with the state)
\end{itemize}
\end{itemize}
\item Do 1.-3. $L\times L$ times (one MC cycle)
\item Update mean values 
\item Reapeat 1.-6. untill enough statistics is sampled, the desired number of MC cycles
\end{enumerate}


\textbf{Psedocode:}
\begin{lstlisting}
for numberOfTemperatures:
{
	//create initial state here
	//calculate initial energy and magnetization here
	for numberoOfMCcycles:
	{
		for numberOfspins:
		{
			//do one spin flip here
		}
		//update mean values here
		//print mean values to file here
	}	
	//or print values to file here
}

//then read data from file and plot in python
\end{lstlisting}


for some of the files temperature loop is left in python code, which also compiles and runs the cpp code

should discard contributions to mean vals before equilibrium


\subsection{Coding $\Delta E$, $\Delta \mathcal{M}$  and w efficiently}
We wish to run the simulations for large numbers of Monte Carlo cycles $~10^5$. It is therefore very important to code the calculation of $\Delta E$ efficiently because it will be calculated $N$ times each Monte Carlo cycle. 

The difference in the energy can be expressed as:
\begin{align*}
\Delta E = E_2 - E_1 = -J\sum_{<kl>}^N s_{k,2}s_{l,2} + J\sum_{<kl>}^N s_{k,1}s_{l,1}
\end{align*}
where the $l$ index is the spin that was flipped and $k$ the neighbours of $l$.  We only flip one spin at a time, so the neighbours of $s_l$ are unchanged meaning that $s_{k,2} = s_{k,1} = s_k$. The difference in energy can then be written as:
\[
\Delta E = J\sum_{<kl>}^N s_ks_{l,1} - J\sum_{<kl>}^N s_ks_{l,2} = J\sum_{<kl>}^N s_k(s_{l,1} - s_{l,2} )
\]
The spin can only take two values, so $s_{l,1}$ is either 1 or -1. If $s_{l,1}=1$ then after the flip $s_{l,2} = -1$ and $s_{l,1} - s_{l,2} = 1 - (-1) = 2$. If $s_{l,1}=-1$ then after the flip $s_{l,2} = 1$ and $s_{l,1} - s_{l,2} = -1 - 1 = -2$. We can therefore write $s_{l,1} - s_{l,2} = 2s_{l,1}$ and then we obtain:
\[
\Delta E = J\sum_{<kl>}^N s_k\cdot 2s_{l,1} = 2Js_{l,1}\sum_{<k>}^N s_k
\]
which is the same as in theory????when doing by hand energy?

Similarly for the magnetization:
\begin{align*}
\Delta \mathcal{M} &= \mathcal{M}_2 - \mathcal{M}_1 = \sum_i^N s_{i,2} - \sum_i^N s_{i,1} = \sum_i^N (s_{i,2} -  s_{i,1}) = s_{l,2} - s_{l,1} = -2s_{l,1}\\
\Rightarrow \mathcal{M}_2 &= \mathcal{M}_1 - 2s_{l,1}
\end{align*}

This way of calculating the difference in energy and magnetization makes the algorithm for flipping one spin run faster than orther solutions. We also want to avoid to calculate the exponential of $Delta E $, the value of $w=e^{-\beta\delta E}$ for every time the trial energy is higher than the current energy. We can avoid this by noticing that there are only 5 possible values $\Delta E$ can take when we only flip one spin at a time (in the two dimentional case) $\Delta E \in \{-8, -4, 0, 4, 8\}$. So the energy minimum have to change in steps of 4, and maximum in steps of 8 when we flip one spin at a time. Then there are also only 5 possible values of $w$ for a given temperature. We can exploit this further by realizing that we only use $w$ when $\Delta E > 0 \Rightarrow \Delta E \in \{4, 8\}$. For a given temperature we then calculate the two values of $w$ once and pass it on to the metropolis test which uses the value corresponding to $\Delta E$. 


something something random initial state ??? p. 439, dependence T


\section{"Experiment"}
\subsection{Testing the implementation of the model and algorithm}
First we will compare the results for the metropolis algorithm with the theoretical values for the $L=2$ case calculated in section (?). All calculations and results in this report is per spin, meaning that we have divided the values with the total number of spins $N=L^2$. 

In figure \ref{fig:theory E} we see the expectation value of the energy (top), energy squared (middle) and the heat capacity (bottom) as a function of the temperature. The simulation was run for $5\cdot10^5$ Monte Carlo Cycles. The simulation was started with an initial state with all spins up. In figure 

\begin{figure}[htp]
\centering
\includegraphics[width=0.8\textwidth]{figures_L2/theoryE.png}
\caption{Expectation value of the energy (top), energy squared (middle) and the heat capacity (bottom) per spin as a function of the temperature. The numerical calculation was run for $5\cdot10^5$ Monte Carlo Cycles with a initial state of all spins up (\texttt{initial\_state=1}) with $L=2$. The numerical (blue line) and the teoretical (green line) values are plotted together.}
\label{fig:theory E}
\end{figure}

\begin{figure}[htp]
\centering
\includegraphics[width=0.8\textwidth]{figures_L2/theoryM.png}
\caption{ Expectation value of the absolute magnetization (top), magnetization squared (middle) and the susceptibility (bottom) per spin as a function of the temperature. The numerical calculation was run for $5\cdot10^5$ Monte Carlo Cycles with a initial state of all spins up (\texttt{initial\_state=1}) with $L=2$. The numerical (blue line) and the teoretical (green line) values are plotted together.}
\label{fig:theory M}
\end{figure}

The numerical values agree very well with the theoretical values. In figure \ref{fig: error E} we see the absolute error in the Expectation value of the energy (top), energy squared (middle) and the heat capacity (bottom) per spin as a function of Monte Carlo cycles. In figure \ref{fig: error M} we see the absolute error in the expectation value of the absolute magnetization (top), magnetization squared (middle) and the susceptibility (bottom) as a function of Monte Carlo Cycles. The temperature in both plot \ref{fig: error E} and \ref{fig: error M} was held at $T=1$.

The spin system with $L=2$ is very small so it takes very few MC cycles to reach the equlilibrium state, which for low temperatures are close to the lowes energy state. I does therefore not matter which initial state the system start out with. The error in the numerical calculcations will not depend on the initial state, but on the amount of statistics, how many MC cycles. In the simulation run in figure \ref{fig: error E} we have used a initial state of all spins up (\texttt{initial\_state=1}) which is the state with the lowest energy.  

In the figures \ref{fig: error E} and \ref{fig: error M} we see that the error falls quicly and stabilizes after $~2\cdot 10^5$ MC cycles. The heat capacity has the largest error with absolute error below 0.01 after stabilizing. Most of the error comes from the expectation value of the energy squared while the error in the expectation value of the energy is much smaller, $~0.002$. The error in the suceptibility falls below 0.002, smallest error is for the the expectation value of the absolute magnetization of less than 0.0005.

From looking at figure \ref{fig: error E} and \ref{fig: error M} it seems reasonable to choose the number of MC cycles to be more than $2\cdot10^5$.

\begin{figure}[htp]
\centering
\includegraphics[width=0.8\textwidth]{figures_L2/error_E_MC.png}
\caption{Absolute error in the expectation value of the energy (top), energy squared (middle) and the heat capacity (bottom) a function of Monte Carlo Cycles with a initial state of all spins up (\texttt{initial\_state=1}) with $L=2$. The temperature was held at $T=1$. }
\label{fig: error E}
\end{figure}

\begin{figure}[htp]
\centering
\includegraphics[width=\textwidth]{figures_L2/error_M_MC.png}
\caption{Absolute error in the expectation value of the absolute magnetization (top), magnetization squared (middle) and the susceptibility (bottom) as a function of Monte Carlo Cycles with a initial state of all spins up (\texttt{initial0.8\_state=1}) with $L=2$. The temperature was held at $T=1$. }
\label{fig: error M}
\end{figure}

\subsection{Equilibrium time}
We will now look at a larger system with $L=20$ and study the equilibrium time, how many Monte Carlo cycles the system uses to reach the stable equilibrium state. The calculations of mean values should starte after the equilibrium state is reached so that the statistics are not 'ruined' by the path from the initial state to the equilibrium state. We will therefore try to decide the equilibrium time. We will look at two temperatures, $T\in \{1.0, 2.4\}$ and start in both a random and ordered initial state. For the ordered state we will have all spins up. 

In figure \ref{fig: equilibrium T1} we see the expectation value of the energy per spin as a function of Monte Carlo cycles at the top and the expectation value of the absolute magnetization per spin as a function of Monte Carlo cycles on the bottom. The plots to the left are with the initial state ordered and we can clearly see that the system stabelazies around a value both for the mean energy and mean absolute magnetization. 

The plots to the right in figure \ref{fig: equilibrium T1} started with a random initial state and have a different unexpected behaviour. We see that the expectation values have a 'hump' before the stabilizing. The same strange behaviour can be observed in figure \ref{fig: equilibrium T2} which is the same plot, but for a higher temperature $T=2.4$. We see that the plots with random initial state are very smooth and do not have any statistically behaviour. 

\begin{figure}[htp]
\centering
\includegraphics[width=\textwidth]{equilibrium/equilibrium_T1_MC.png}
\caption{Top: Expectation value of the energy per spin as a function of Monte Carlo cycles. Bottom:  Expectation value of the absolute magnetization per spin as a function of Monte Carlo cycles. To the left the initial state is ordered and to the right the initial state is random. The size of the lattice is $L=20$ and the temperature is $T=1$.}
\label{fig: equilibrium T1}
\end{figure}

\begin{figure}[htp]
\centering
\includegraphics[width=\textwidth]{equilibrium/equilibrium_T2_MC.png}
\caption{Top: Expectation value of the energy per spin as a function of Monte Carlo cycles. Bottom:  Expectation value of the absolute magnetization per spin as a function of Monte Carlo cycles. To the left the initial state is ordered and to the right the initial state is random. The size of the lattice is $L=20$ and the temperature is $T=2.4$.}
\label{fig: equilibrium T2}
\end{figure}

In figure \ref{fig: accepted T1} we see the accepted configurations per spin as a function of MC cycles for both ordered and random initial state for the temperature $T=1$. We see that the number of accepted configurations per spin grows as number of MC cycles increase and then flats out. For the random initial state we see the oposite behaviour, the number of accepted configurations decrease as a function of MC cycles. We would expect that for a low temperature as $T=1$ the equilibrium state are closer to the orderes state than the random state. It is natural that for the random initial state the number of accepted configurations are very large in the start as the system is 'trying' to reach the equilibrium state, and when the equilibrium state is found the number of accepted states flats out. 

The corresponding plot for $T=2.4$ is shown in figure \ref{fig:  accepted T2}. We see that the number of accepted counfigurations flats out for the ordered and random initial state here too. But the Random initial state have a very sooth slope, which the low temperature case did not have. 


\begin{figure}[htp]
\includegraphics[width=\textwidth]{equilibrium/accepted_T1_MC.png}
\caption{Accepted configurations per spin as a function of MC cycles. Top: Ordered initial state (all spinst up). Bottom: Random initial state. The temperature is $T=1$.}
\centering
\label{fig: accepted T1}
\end{figure}

\begin{figure}[htp]
\includegraphics[width=\textwidth]{equilibrium/accepted_T2_MC.png}
\caption{Accepted configurations per spin as a function of MC cycles. Top: Ordered initial state (all spinst up). Bottom: Random initial state. The temperature is $T=2.4$.}
\centering
\label{fig:  accepted T2}
\end{figure}



In this subsection we have looked at the behaviour of the $L=20$ system as a function of Monte Carlo cycles. There are some unexpected non-stastistical behaviour in the plost with the random initial state that we have no explaination for. We have therefor decided to always start with the ordered initial state in the firther calculations. For larger temperatures and $L$ this could mean that we would have to use unneccecary many MC cycles to reach the equilbrium state, but we choose to ignore this in this paper. 

For both temperatures the system stabilized for $~10^5$ MC cycles so we will use a equilibrium time of $t_{eq} = 2\cdot10^5$ MC cycles in this paper. 

In figure \ref{fig:  accepted Trange} we see the number of accepted configurations per spin as a function temperature for the ordered initial state. We start the simulation in the ordered state. It is as axpected that the number of accepted configurations increase with temperarure when the total number of Monte Carlo cycles is much larger ($500000$) than the euilibrium time. This is because when the temperature is low it is very unlikely to flip a spin after the equilibrium state is reached because the state is very close to the ground state. The probability to flip a spin increases as the temperarure increases because the spread in energy is larger, $\sigma_E$ is larger. Thus the number of accepted cycles increase as a function of temperature.

\begin{figure}[htp]
\includegraphics[width=\textwidth]{equilibrium/accepted_Trange_initial1.png}
\caption{Accepted configurations per spin as a function temperature. Top: Ordered initial state (all spinst up). Bottom: Random initial state. The total number of monte carlo cycles is 500000 for the $L=20$ and ordered initial state. }
\centering
\label{fig:  accepted Trange}
\end{figure}

\subsection{Probability}
In this subsection we will look at the probability for a given energy and see it this matches our physical intuition about the system. We will look at the case $L=20$ and the temperatures $T\in \{1.0, 2.0, 1.4\}$.

\begin{figure}[htp]
\includegraphics[width=\textwidth]{equilibrium/probability.png}
\caption{Probability as a function of energy per spin for the temperatures $T\in \{1.0, 2.0, 1.4\}$ with the coresponding standard deviations $\sigma_E \in \{0.15, 1.71, 2.8 \}$. }
\centering
\label{fig:  probability}
\end{figure}

\subsection{Studying .... close to the critical temp}


\subsection{Calculations to find $T_c$}


\section{Results and output}


\section{Discussion and experiences}





\newpage

\begin{enumerate}

\item[a)] Assume we have only two spins in each dimension, that is $L=2$.
Find the closed form expression for the partition function and the corresponding
expectations values for
for $E$, $|{\cal M}|$, the specific heat $C_V$ and the susceptibility $\chi$ 
as functions of  $T$ using periodic boundary conditions.



\item[b)] 
Write now a code for the Ising model which computes the mean energy 
$E$, mean magnetization 
$|{\cal M}|$, the specific heat $C_V$ and the susceptibility $\chi$ 
as functions of  $T$ using periodic boundary conditions for 
$L=2$ in the $x$ and $y$ directions. 
Compare your results with the expressions from a)
for  a  temperature $T=1.0$ (in units of $kT/J$). 

How many Monte Carlo cycles do you need in order to achieve a good agreeement?


\item[c)]
 
We choose now a square lattice with $L=20$ spins in the $x$ and $y$ directions. 

In [b) we did not study carefully how many Monte Carlo cycles were needed in order to reach the most likely state. Here
we want to perform a study of the time (here it corresponds to the number 
of Monte Carlo cycles) one needs before one reaches an equilibrium situation 
and can start computing various expectations values. Our 
first attempt is a rough and plain graphical
one, where we plot various expectations values as functions of the number of Monte Carlo cycles.

Choose first a temperature of $T=1.0$ (in units of $kT/J$) and study the 
mean energy and magnetisation (absolute value) as functions of the number of Monte Carlo cycles.
Use both an ordered (all spins pointing in one direction) and a random
spin orientation as starting configuration. 
How many Monte Carlo cycles do you need before you reach an equilibrium situation?
Repeat this analysis for $T=2.4$. 

Make also a plot of the total number of accepted configurations 
as function of the total number of Monte Carlo cycles. How does the number of
accepted configurations behave as function of temperature $T$?


\item[d)] Compute thereafter the probability 
$P(E)$ for the previous system with $L=20$ and the same temperatures.
You compute this probability by simply counting the number of times a 
given energy appears in your computation. Start the computation after 
the steady state situation has been reached.
Compare your results with the computed variance in energy 
$\sigma^2_E$ and discuss the behavior you observe. 
\end{enumerate}

Near $T_C$ we can characterize the behavior of many physical quantities
by a power law behavior.
As an example the mean magnetization is given by
\begin{equation}
  \langle {\cal M}(T) \rangle \sim \left(T-T_C\right)^{\beta},
\end{equation}
where $\beta=1/8$ is a so-called critical exponent. A similar relation
applies to the heat capacity 
\begin{equation}
  C_V(T) \sim \left|T_C-T\right|^{\alpha},
\end{equation}
and the susceptibility
\begin{equation}
  \chi(T) \sim \left|T_C-T\right|^{\gamma},
\end{equation}
with $\alpha = 0$ and $\gamma = 7/4$.
Another important quantity is the correlation length, which is expected
to be of the order of the lattice spacing for $T>> T_C$. Because the spins
become more and more correlated as $T$ approaches $T_C$, the correlation
length increases as we get closer to the critical temperature. The divergent
behavior of $\xi$ near $T_C$ 
is
\begin{equation}
  \xi(T) \sim \left|T_C-T\right|^{-\nu}.
  \label{eq:xi}
\end{equation}
A second-order phase transition is characterized by a
correlation length which spans the whole system.
Since we are always limited to a finite lattice, $\xi$ will
be proportional with the size of the lattice. 
Through so-called finite size scaling relations
it is possible to relate the behavior at finite lattices with the 
results for an infinitely large lattice.
The critical temperature scales then as
\begin{equation}
 T_C(L)-T_C(L=\infty) = aL^{-1/\nu},
 \label{eq:tc}
\end{equation}
with  $a$ a constant and  $\nu$ defined in Eq.~(\ref{eq:xi}).
We set $T=T_C$ and obtain a mean magnetisation
\begin{equation}
  \langle {\cal M}(T) \rangle \sim \left(T-T_C\right)^{\beta}
  \rightarrow L^{-\beta/\nu},
  \label{eq:scale1}
\end{equation}
a heat capacity
\begin{equation}
  C_V(T) \sim \left|T_C-T\right|^{-\gamma} \rightarrow L^{\alpha/\nu},
  \label{eq:scale2}
\end{equation}
and susceptibility
\begin{equation}
  \chi(T) \sim \left|T_C-T\right|^{-\alpha} \rightarrow L^{\gamma/\nu}.
  \label{eq:scale3}
\end{equation}

\begin{enumerate}
\item [e)]  We wish to study the behavior of the Ising model in two dimensions close to the 
critical temperature as a function of the lattice size $L\times L$.
Calculate the expectation values 
for $\langle E\rangle$ and $\langle |{\cal M}|\rangle$,
the specific heat $C_V$ and the susceptibility $\chi$
as functions  of $T$ for $L=20$, $L=40$, $L=60$ and $L=80$ for $T\in [2.0,2.4]$
with a step in temperature $\Delta T=0.05$ or smaller. 
Plot  $\langle E\rangle$, $\langle 1{\cal M}1\rangle$, $C_V$ and $\chi$ 
as functions of $T$. Can you see an indication of a phase transition?

Use the absolute value $\langle |{\cal M}|\rangle$ when you evaluate $\chi$.

You should parallelize the code using either OpenMP or MPI.
\item[f)]  Use Eq.~(\ref{eq:tc}) and the exact result
$\nu=1$ in order to estimate $T_C$ in the thermodynamic limit $L\rightarrow \infty$
using your simulations with $L=20$, $L=40$, $L=60$ and $L=80$
The exact result for the critical temperature (after Lars Onsager) is
$kT_C/J=2/ln(1+\sqrt{2})\approx 2.269$ with $\nu=1$.
\end{enumerate}

\section*{Background literature}
If you wish to read more about the Ising model and statistical physics here are two suggestions.
\begin{enumerate}
\item M.~Plischke and B.~Bergersen, Equilibrium Statistical Physics,
Prentice-Hall, see chapters 5 and 6.
\item M.~E.~J.~Newman and T.~Barkema, Monte Carlo methods in statistical physics, Oxford, see chapters 3 and 4.

\end{enumerate}
\end{document}






